
'''
Title:        PowerGen Toolkit
Description:  PowerGen (Power Generation Dataset) Toolkit for Generating Resources Utlization and Corresponding Power Consumption in Edge and Cloud Computing Data Centers
Licence:      GPL - http://www.gnu.org/copyleft/gpl.html

Copyright (c) 2024, Intelligent Distributed Computing and Systems (INDUCE) Lab, The United Arab Emirates University, United Arab Emirates

If you are using any ideas, algorithms, packages, codes, datasets, workload, results, and plots, included in the power-modeling directory please cite
the following paper:

https://doi.org/TBD">Leila Ismail, and Huned Materwala, "PowerGen: Resources Utilization
and Power Consumption Data Generation Framework for Energy Prediction in Edge and Cloud Computing",
ANT 2024

'''


This directory contains seven sub-directories which are used to generate results for use case 1

1) models-training-validation: This directory contains the python code used to develop and validate power models as part of use case 1. The code will use the 'Training and validation dataset.csv' file from the 'Datasets' folder to develop 8 power models (Model 1 - Model 8 in the paper). The code will save each model in the 'Results_Developed models' folder. The plot representing the actual power consumption value and the predicted power consumption values (using model 1 - model 8) using the validation dataset will be saved in the 'Results_Plots' folder. The code will compute the Mean Absolute Error for each model and will store it in a dataframe. The code will then write the dataframe values in a excel file and save the file in the 'Results_Metrics' folder.

2) models-testing: This directory contains the python codes for testing the developed models using testing dataset. A separate python code for a testing dataset generated using a benchmark/application is provided. Each code will use the corresponding testing dataset from the 'Datasets' folder and the developed models from the 'Results_Developed models' folder. The code will plot the actual power consumption value and the predicted power consumption values (using model 1 - model 8) using the corresponding testing dataset and will save the plot in the 'Results_Plots' folder. The code will compute the Mean Absolute Error for each model using the testing dataset and will store it in a dataframe. The code will then write the dataframe values in a excel file and save the file in the 'Results_Metrics' folder.

3) models-performance-evaluation: This directory contains the python code to plot the MAE for the developed models for the validation and testing datasets. The code will use the excel file containing the MAE results from the 'results-metrics' folder and will  plot a spider plot representing MAE for each model. The plot will be then saved in the 'results-plot' folder. NOTE: The Plots represetning MAEs for validation and testing datasets are not included in our paper. The MAEs values are presented in a table for clarity.

4) Datasets: This directory contains the training and validation dataset which is generated using CPU load generator, stress, vdbench, and iperf3 tools. This dataset is used to train and validate the models under study. In addition, this folder contains an excel sheet with a testing dataset which is generated by running each benchmark/application (i.e., sysbench, mencoder, PARSEC portfolio, k-means clustering, and PARSEC streamcluster). This dataset is used to test the power models considered in the paper.

5) results-trained-models: This directory contains the developed power models that are saved when the 'Training_&_Validation.py' code located in the 'models-training-validation' folder is executed. These models are used by the codes located in 'models-testing' folder for testing the developed models.

6) results-metrics: This directory contains excel sheets which has the MAE values for the power models when evaluated using the validation and testing datasets. These files are generated and saved when the python codes located in 'models-training-validation' and 'models-testing' folders are executed.

7) results-plots: This directory contains the plots representing the acutal and predicted power consumption values for validation and testing datasets. In addition, it includes the plots representing MAE values for the power models when evaluated using validation and testing datasets. These plots are generated and saved when the python codes in the 'models-training-validation', 'models-testing', and 'models-performance-evaluation' folders are executed.

---------------------------------------------------------
Steps to reproduce the results for power modeling scenario
---------------------------------------------------------
1. Run the 'Training_&_Validation.py' code from the 'model-training-validation' folder. The developed models, corresponding plot, and excel file containing the MAE values will be saved in the 'results-trained-models', 'results-plots', and 'results-metrics' folders respectively.

2. Run the python codes located in the 'models-testing' folder. The corresponding plots and excel files containing the MAE values will be saved in the 'results-plots' and 'results-metrics' folders respectively.

3. Run the python codes located in the 'models-performance-evaluation' folder. The corresponding plots will be saved in the 'results-plots' folders.